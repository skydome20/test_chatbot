{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /home/skydome20/Desktop/dbot/dbot.py3/jieba_dict/dict.txt.big ...\n",
      "Loading model from cache /tmp/jieba.u300776cf1c5f564361e07846b411a882.cache\n",
      "Loading model cost 1.506 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "Building prefix dict from /home/skydome20/Desktop/dbot/dbot.py3/jieba_dict/dict.txt.big ...\n",
      "2017-02-22 14:08:51,284 : DEBUG : Building prefix dict from /home/skydome20/Desktop/dbot/dbot.py3/jieba_dict/dict.txt.big ...\n",
      "Loading model from cache /tmp/jieba.u300776cf1c5f564361e07846b411a882.cache\n",
      "2017-02-22 14:08:51,293 : DEBUG : Loading model from cache /tmp/jieba.u300776cf1c5f564361e07846b411a882.cache\n",
      "Loading model cost 2.221 seconds.\n",
      "2017-02-22 14:08:53,514 : DEBUG : Loading model cost 2.221 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "2017-02-22 14:08:53,523 : DEBUG : Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= No filter ===============\n",
      "1st keywords:['客運', '致死']\n",
      "2nd keywords:52\n",
      "[('客運', 41), ('業者', 28), ('票價', 21), ('駕駛', 15), ('遊覽車', 14), ('台北', 12), ('調漲', 12), ('司機', 10), ('宜蘭', 8), ('檢查', 8)]\n",
      "['業者', '票價', '駕駛', '遊覽車', '台北']\n",
      "3rd keywords:147\n",
      "[('遊覽車', 103), ('駕駛', 79), ('司機', 43), ('台北', 35), ('業者', 24), ('行程', 23), ('台灣', 20), ('旅遊', 18), ('工時', 16), ('表示', 14)]\n",
      "['司機', '行程', '台灣', '旅遊', '工時']\n",
      "4nd keywords:176\n",
      "[('台灣', 133), ('司機', 56), ('遊覽車', 47), ('駕駛', 44), ('行程', 26), ('旅遊', 25), ('工時', 24), ('小時', 15), ('日本', 12), ('時間', 10)]\n",
      "['小時', '日本', '時間']\n"
     ]
    }
   ],
   "source": [
    "%run main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /home/skydome20/Desktop/dbot/dbot.py3/jieba_dict/dict.txt.big ...\n",
      "Loading model from cache /tmp/jieba.u300776cf1c5f564361e07846b411a882.cache\n",
      "Loading model cost 2.615 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "Building prefix dict from /home/skydome20/Desktop/dbot/dbot.py3/jieba_dict/dict.txt.big ...\n",
      "2017-02-23 10:53:51,319 : DEBUG : Building prefix dict from /home/skydome20/Desktop/dbot/dbot.py3/jieba_dict/dict.txt.big ...\n",
      "Loading model from cache /tmp/jieba.u300776cf1c5f564361e07846b411a882.cache\n",
      "2017-02-23 10:53:51,326 : DEBUG : Loading model from cache /tmp/jieba.u300776cf1c5f564361e07846b411a882.cache\n",
      "Loading model cost 2.439 seconds.\n",
      "2017-02-23 10:53:53,765 : DEBUG : Loading model cost 2.439 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "2017-02-23 10:53:53,785 : DEBUG : Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Similar filter ===============\n",
      "1st keywords:['客運', '致死']\n",
      "2nd keywords:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-23 11:05:40,547 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2017-02-23 11:05:40,581 : INFO : built Dictionary(3483 unique tokens: ['不支', '列為', '左側', '轉乘', '辭世']...) from 44 documents (total 12609 corpus positions)\n",
      "2017-02-23 11:05:40,619 : INFO : collecting document frequencies\n",
      "2017-02-23 11:05:40,626 : INFO : PROGRESS: processing document #0\n",
      "2017-02-23 11:05:40,628 : INFO : calculating IDF weights for 44 documents and 3482 features (7850 matrix non-zeros)\n",
      "2017-02-23 11:05:40,637 : INFO : using serial LSI version on this node\n",
      "2017-02-23 11:05:40,645 : INFO : updating model with new documents\n",
      "2017-02-23 11:05:40,667 : INFO : preparing a new chunk of documents\n",
      "2017-02-23 11:05:40,676 : INFO : using 100 extra samples and 2 power iterations\n",
      "2017-02-23 11:05:40,687 : INFO : 1st phase: constructing (3483, 110) action matrix\n",
      "2017-02-23 11:05:40,693 : INFO : orthonormalizing (3483, 110) action matrix\n",
      "2017-02-23 11:05:41,044 : INFO : 2nd phase: running dense svd on (110, 44) matrix\n",
      "2017-02-23 11:05:41,068 : INFO : computing the final decomposition\n",
      "2017-02-23 11:05:41,075 : INFO : keeping 10 factors (discarding 54.578% of energy spectrum)\n",
      "2017-02-23 11:05:41,080 : INFO : processed documents up to #44\n",
      "2017-02-23 11:05:41,088 : INFO : topic #0(2.059): 0.302*\"元\" + 0.258*\"票價\" + 0.224*\"0\" + 0.210*\"3月1日\" + 0.172*\"39\" + 0.164*\"台北\" + 0.161*\"調漲\" + 0.153*\"調整\" + 0.137*\"日統\" + 0.128*\"統聯\"\n",
      "2017-02-23 11:05:41,093 : INFO : topic #1(1.756): -0.327*\"勞工局\" + -0.189*\"檢查\" + -0.170*\"低價\" + -0.162*\"勞動\" + -0.157*\"遊覽車\" + -0.153*\"鄭素玲\" + -0.147*\"旅行團\" + -0.146*\"旅行社\" + -0.139*\"違法\" + -0.128*\"駕駛\"\n",
      "2017-02-23 11:05:41,094 : INFO : topic #2(1.494): -0.188*\"排班\" + 0.160*\"元\" + 0.148*\"39\" + -0.143*\"一休\" + -0.133*\"王國\" + -0.127*\"一例\" + -0.123*\"港口\" + -0.116*\"運價\" + 0.114*\"勞工局\" + -0.114*\"上路\"\n",
      "2017-02-23 11:05:41,098 : INFO : topic #3(1.405): -0.216*\"車車\" + -0.197*\"遊覽\" + -0.181*\"遊覽車\" + -0.163*\"這輛\" + -0.163*\"哪裡\" + -0.148*\"19年\" + -0.146*\"10年\" + -0.131*\"齡\" + -0.113*\"33\" + -0.111*\"死\"\n",
      "2017-02-23 11:05:41,102 : INFO : topic #4(1.348): 0.194*\"39\" + -0.173*\"優惠\" + 0.167*\"排班\" + 0.165*\"元\" + 0.130*\"日統\" + 0.127*\"王國\" + -0.124*\"票價\" + -0.119*\"新聞稿\" + 0.109*\"運價\" + 0.109*\"港口\"\n",
      "2017-02-23 11:05:41,103 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n",
      "2017-02-23 11:05:41,117 : INFO : creating matrix with 44 documents and 10 features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of news is :44\n",
      "[('客運', 38), ('業者', 23), ('票價', 21), ('台北', 15), ('遊覽車', 15), ('司機', 13), ('調漲', 12), ('駕駛', 11), ('調整', 9), ('公車', 8)]\n",
      "['業者', '票價', '台北', '遊覽車', '司機']\n",
      "3rd keywords:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-23 11:16:52,656 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2017-02-23 11:16:52,798 : INFO : built Dictionary(11344 unique tokens: ['仍停留', '心態', '漲並', '李鴻鈞', '劣質']...) from 154 documents (total 57349 corpus positions)\n",
      "2017-02-23 11:16:52,938 : INFO : collecting document frequencies\n",
      "2017-02-23 11:16:52,943 : INFO : PROGRESS: processing document #0\n",
      "2017-02-23 11:16:52,964 : INFO : calculating IDF weights for 154 documents and 11343 features (37432 matrix non-zeros)\n",
      "2017-02-23 11:16:52,996 : INFO : using serial LSI version on this node\n",
      "2017-02-23 11:16:53,006 : INFO : updating model with new documents\n",
      "2017-02-23 11:16:53,156 : INFO : preparing a new chunk of documents\n",
      "2017-02-23 11:16:53,187 : INFO : using 100 extra samples and 2 power iterations\n",
      "2017-02-23 11:16:53,195 : INFO : 1st phase: constructing (11344, 110) action matrix\n",
      "2017-02-23 11:16:53,215 : INFO : orthonormalizing (11344, 110) action matrix\n",
      "2017-02-23 11:16:54,086 : INFO : 2nd phase: running dense svd on (110, 154) matrix\n",
      "2017-02-23 11:16:54,126 : INFO : computing the final decomposition\n",
      "2017-02-23 11:16:54,137 : INFO : keeping 10 factors (discarding 77.919% of energy spectrum)\n",
      "2017-02-23 11:16:54,147 : INFO : processed documents up to #154\n",
      "2017-02-23 11:16:54,152 : INFO : topic #0(2.636): 0.150*\"駕駛\" + 0.126*\"遊覽車\" + 0.116*\"行程\" + 0.116*\"司機\" + 0.112*\"休息\" + 0.112*\"工時\" + 0.100*\"小時\" + 0.097*\"交通部\" + 0.091*\"林美珠\" + 0.088*\"一日遊\"\n",
      "2017-02-23 11:16:54,159 : INFO : topic #1(1.862): 0.292*\"元\" + 0.287*\"調漲\" + 0.274*\"票價\" + 0.235*\"元漲\" + 0.225*\"漲幅\" + 0.191*\"漲價\" + 0.178*\"統聯\" + 0.162*\"漲\" + 0.147*\"客運\" + 0.147*\"台北\"\n",
      "2017-02-23 11:16:54,161 : INFO : topic #2(1.697): 0.224*\"一日遊\" + -0.207*\"林美珠\" + 0.183*\"行程\" + 0.157*\"雙\" + 0.154*\"旅遊\" + -0.134*\"雇主\" + 0.126*\"國旅\" + 0.126*\"商品\" + 0.125*\"燦星\" + 0.122*\"採取\"\n",
      "2017-02-23 11:16:54,162 : INFO : topic #3(1.654): 0.285*\"林美珠\" + 0.188*\"雇主\" + -0.163*\"友力\" + 0.160*\"拘束\" + -0.146*\"靠行\" + 0.133*\"休息\" + -0.133*\"鄭寶清\" + 0.122*\"工時\" + 0.107*\"脫離\" + -0.102*\"通運\"\n",
      "2017-02-23 11:16:54,167 : INFO : topic #4(1.531): 0.181*\"鄭寶清\" + 0.172*\"靠行\" + 0.161*\"友力\" + -0.132*\"安全帶\" + 0.117*\"生計\" + 0.105*\"處分\" + -0.104*\"煞車\" + -0.097*\"乘客\" + 0.091*\"林美珠\" + 0.087*\"交通部\"\n",
      "2017-02-23 11:16:54,169 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n",
      "2017-02-23 11:16:54,195 : INFO : creating matrix with 154 documents and 10 features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of news is :154\n",
      "[('遊覽車', 110), ('司機', 86), ('駕駛', 53), ('台北', 34), ('行程', 22), ('工時', 20), ('業者', 20), ('旅行社', 19), ('旅遊', 17), ('台灣', 15)]\n",
      "['駕駛', '行程', '工時', '旅行社', '旅遊']\n",
      "4nd keywords:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-23 11:27:26,170 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2017-02-23 11:27:26,337 : INFO : built Dictionary(10211 unique tokens: ['仍停留', '桃竹', '人煙稀少', '變為', '傾']...) from 143 documents (total 49413 corpus positions)\n",
      "2017-02-23 11:27:26,455 : INFO : collecting document frequencies\n",
      "2017-02-23 11:27:26,461 : INFO : PROGRESS: processing document #0\n",
      "2017-02-23 11:27:26,483 : INFO : calculating IDF weights for 143 documents and 10210 features (32642 matrix non-zeros)\n",
      "2017-02-23 11:27:26,526 : INFO : using serial LSI version on this node\n",
      "2017-02-23 11:27:26,527 : INFO : updating model with new documents\n",
      "2017-02-23 11:27:26,640 : INFO : preparing a new chunk of documents\n",
      "2017-02-23 11:27:26,657 : INFO : using 100 extra samples and 2 power iterations\n",
      "2017-02-23 11:27:26,675 : INFO : 1st phase: constructing (10211, 110) action matrix\n",
      "2017-02-23 11:27:26,692 : INFO : orthonormalizing (10211, 110) action matrix\n",
      "2017-02-23 11:27:27,620 : INFO : 2nd phase: running dense svd on (110, 143) matrix\n",
      "2017-02-23 11:27:27,641 : INFO : computing the final decomposition\n",
      "2017-02-23 11:27:27,647 : INFO : keeping 10 factors (discarding 75.524% of energy spectrum)\n",
      "2017-02-23 11:27:27,653 : INFO : processed documents up to #143\n",
      "2017-02-23 11:27:27,661 : INFO : topic #0(2.766): -0.127*\"駕駛\" + -0.110*\"旅遊\" + -0.107*\"一日遊\" + -0.107*\"雙\" + -0.107*\"行程\" + -0.104*\"觀光局\" + -0.104*\"司機\" + -0.102*\"遊覽車\" + -0.095*\"工時\" + -0.095*\"業者\"\n",
      "2017-02-23 11:27:27,667 : INFO : topic #1(1.950): 0.135*\"林美珠\" + 0.129*\"工作時間\" + -0.126*\"一日遊\" + -0.111*\"燦星\" + 0.109*\"勞動部\" + 0.107*\"雇主\" + -0.104*\"國旅\" + -0.100*\"雙\" + -0.099*\"觀光局\" + -0.099*\"旅遊\"\n",
      "2017-02-23 11:27:27,669 : INFO : topic #2(1.855): -0.180*\"妥適\" + -0.175*\"檢視\" + -0.173*\"應\" + -0.140*\"應使\" + -0.131*\"大原\" + -0.130*\"原則\" + -0.126*\"距離\" + -0.122*\"公里\" + -0.122*\"之\" + -0.116*\"加計\"\n",
      "2017-02-23 11:27:27,670 : INFO : topic #3(1.725): -0.149*\"蘋果\" + -0.123*\"林全\" + -0.116*\"毆\" + -0.116*\"下月\" + -0.116*\"公分\" + -0.116*\"通車\" + -0.116*\"限水\" + -0.116*\"裂\" + -0.108*\"新北\" + -0.098*\"起\"\n",
      "2017-02-23 11:27:27,675 : INFO : topic #4(1.697): 0.203*\"投保\" + -0.156*\"工作時間\" + -0.141*\"勞動部\" + -0.139*\"林美珠\" + 0.130*\"周比蒼\" + 0.118*\"周比\" + -0.111*\"雇主\" + 0.110*\"周繼弘\" + 0.107*\"弟弟\" + -0.105*\"勞務\"\n",
      "2017-02-23 11:27:27,677 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n",
      "2017-02-23 11:27:27,704 : INFO : creating matrix with 143 documents and 10 features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of news is :143\n",
      "[('駕駛', 99), ('遊覽車', 61), ('司機', 57), ('旅遊', 47), ('行程', 44), ('工時', 32), ('旅行社', 32), ('業者', 25), ('小時', 21), ('時間', 16)]\n",
      "['小時', '時間']\n"
     ]
    }
   ],
   "source": [
    "%run main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /home/skydome20/Desktop/dbot/dbot.py3/jieba_dict/dict.txt.big ...\n",
      "Loading model from cache /tmp/jieba.u300776cf1c5f564361e07846b411a882.cache\n",
      "Loading model cost 1.609 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "Building prefix dict from /home/skydome20/Desktop/dbot/dbot.py3/jieba_dict/dict.txt.big ...\n",
      "2017-02-22 19:12:29,625 : DEBUG : Building prefix dict from /home/skydome20/Desktop/dbot/dbot.py3/jieba_dict/dict.txt.big ...\n",
      "Loading model from cache /tmp/jieba.u300776cf1c5f564361e07846b411a882.cache\n",
      "2017-02-22 19:12:29,632 : DEBUG : Loading model from cache /tmp/jieba.u300776cf1c5f564361e07846b411a882.cache\n",
      "Loading model cost 2.287 seconds.\n",
      "2017-02-22 19:12:31,920 : DEBUG : Loading model cost 2.287 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "2017-02-22 19:12:31,927 : DEBUG : Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Similar filter ===============\n",
      "1st keywords:['女', '大生', '去', '麵包', '坊', '實習', '被', '索賠']\n",
      "2nd keywords:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-22 19:22:48,707 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2017-02-22 19:22:48,735 : INFO : built Dictionary(2630 unique tokens: ['見狀', '企業', '廚房', '外界', '看起來']...) from 15 documents (total 6069 corpus positions)\n",
      "2017-02-22 19:22:48,754 : INFO : collecting document frequencies\n",
      "2017-02-22 19:22:48,756 : INFO : PROGRESS: processing document #0\n",
      "2017-02-22 19:22:48,757 : INFO : calculating IDF weights for 15 documents and 2629 features (3883 matrix non-zeros)\n",
      "2017-02-22 19:22:48,763 : INFO : using serial LSI version on this node\n",
      "2017-02-22 19:22:48,765 : INFO : updating model with new documents\n",
      "2017-02-22 19:22:48,778 : INFO : preparing a new chunk of documents\n",
      "2017-02-22 19:22:48,780 : INFO : using 100 extra samples and 2 power iterations\n",
      "2017-02-22 19:22:48,782 : INFO : 1st phase: constructing (2630, 110) action matrix\n",
      "2017-02-22 19:22:48,786 : INFO : orthonormalizing (2630, 110) action matrix\n",
      "2017-02-22 19:22:49,054 : INFO : 2nd phase: running dense svd on (110, 15) matrix\n",
      "2017-02-22 19:22:49,064 : INFO : computing the final decomposition\n",
      "2017-02-22 19:22:49,071 : INFO : keeping 10 factors (discarding 20.817% of energy spectrum)\n",
      "2017-02-22 19:22:49,072 : INFO : processed documents up to #15\n",
      "2017-02-22 19:22:49,079 : INFO : topic #0(1.555): 0.271*\"工房\" + 0.262*\"核四\" + 0.217*\"封存\" + 0.208*\"員工\" + 0.160*\"核四廠\" + 0.155*\"預算\" + 0.138*\"億元\" + 0.138*\"麵包\" + 0.129*\"設備\" + 0.126*\"台電\"\n",
      "2017-02-22 19:22:49,083 : INFO : topic #1(1.233): 0.305*\"黃士\" + 0.272*\"福\" + 0.178*\"網友\" + 0.162*\"實習\" + 0.149*\"羅勒\" + 0.144*\"珦\" + 0.144*\"新南\" + 0.129*\"黃\" + 0.120*\"蛋糕\" + 0.111*\"手感\"\n",
      "2017-02-22 19:22:49,084 : INFO : topic #2(1.124): -0.325*\"實習\" + 0.194*\"黃士\" + 0.173*\"福\" + -0.171*\"香港\" + -0.169*\"學生\" + -0.161*\"MBA\" + 0.099*\"羅勒\" + -0.096*\"總部\" + -0.095*\"周世婷\" + -0.094*\"機會\"\n",
      "2017-02-22 19:22:49,090 : INFO : topic #3(1.038): 0.232*\"實習\" + -0.210*\"女孩\" + -0.162*\"小\" + -0.141*\"德國\" + -0.140*\"吃\" + 0.139*\"網友\" + -0.122*\"小女孩\" + 0.117*\"香港\" + -0.108*\"麵包\" + -0.105*\"手作\"\n",
      "2017-02-22 19:22:49,091 : INFO : topic #4(1.000): 0.185*\"女\" + 0.185*\"警方\" + 0.185*\"逮捕\" + 0.142*\"大生\" + 0.124*\"明路\" + 0.124*\"指南\" + 0.124*\"胡姓\" + 0.124*\"來電\" + 0.124*\"車手\" + 0.124*\"前往\"\n",
      "2017-02-22 19:22:49,098 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n",
      "2017-02-22 19:22:49,103 : INFO : creating matrix with 15 documents and 10 features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of news is :15\n",
      "[('麵包', 10), ('工房', 8), ('員工', 7), ('實習', 7), ('黃士', 6), ('封存', 5), ('預算', 4), ('學生', 4), ('台灣', 3), ('核四', 3)]\n",
      "['工房', '員工', '黃士', '封存', '預算', '學生']\n",
      "3rd keywords:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-22 19:33:10,491 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2017-02-22 19:33:10,630 : INFO : built Dictionary(12058 unique tokens: ['菜鳥', '包包', '港中', '東區', '不過']...) from 141 documents (total 56528 corpus positions)\n",
      "2017-02-22 19:33:10,758 : INFO : collecting document frequencies\n",
      "2017-02-22 19:33:10,770 : INFO : PROGRESS: processing document #0\n",
      "2017-02-22 19:33:10,787 : INFO : calculating IDF weights for 141 documents and 12057 features (35080 matrix non-zeros)\n",
      "2017-02-22 19:33:10,820 : INFO : using serial LSI version on this node\n",
      "2017-02-22 19:33:10,823 : INFO : updating model with new documents\n",
      "2017-02-22 19:33:10,963 : INFO : preparing a new chunk of documents\n",
      "2017-02-22 19:33:10,989 : INFO : using 100 extra samples and 2 power iterations\n",
      "2017-02-22 19:33:11,001 : INFO : 1st phase: constructing (12058, 110) action matrix\n",
      "2017-02-22 19:33:11,021 : INFO : orthonormalizing (12058, 110) action matrix\n",
      "2017-02-22 19:33:11,918 : INFO : 2nd phase: running dense svd on (110, 141) matrix\n",
      "2017-02-22 19:33:11,996 : INFO : computing the final decomposition\n",
      "2017-02-22 19:33:12,006 : INFO : keeping 10 factors (discarding 76.803% of energy spectrum)\n",
      "2017-02-22 19:33:12,017 : INFO : processed documents up to #141\n",
      "2017-02-22 19:33:12,033 : INFO : topic #0(2.331): -0.193*\"離職\" + -0.187*\"員工\" + -0.181*\"台鐵\" + -0.147*\"業者\" + -0.144*\"求償\" + -0.129*\"學生\" + -0.127*\"坊\" + -0.111*\"烘焙\" + -0.098*\"春節\" + -0.096*\"老闆\"\n",
      "2017-02-22 19:33:12,042 : INFO : topic #1(2.047): 0.327*\"陽台\" + 0.245*\"金大\" + 0.237*\"蒿\" + 0.237*\"安琪\" + 0.224*\"禽流感\" + 0.180*\"鴿子\" + 0.156*\"金門\" + 0.156*\"干擾\" + 0.156*\"鳥類\" + 0.139*\"恐懼\"\n",
      "2017-02-22 19:33:12,043 : INFO : topic #2(1.921): 0.344*\"台鐵\" + -0.235*\"離職\" + 0.190*\"春節\" + -0.187*\"業者\" + -0.186*\"求償\" + -0.161*\"坊\" + 0.159*\"交通部\" + 0.159*\"休假\" + 0.148*\"曠職\" + 0.140*\"罷工\"\n",
      "2017-02-22 19:33:12,054 : INFO : topic #3(1.818): -0.255*\"台鐵\" + 0.135*\"國際\" + 0.128*\"學生\" + -0.123*\"交通部\" + -0.121*\"春節\" + -0.116*\"休假\" + 0.114*\"香港\" + 0.111*\"課程\" + -0.111*\"員工\" + -0.110*\"罷工\"\n",
      "2017-02-22 19:33:12,055 : INFO : topic #4(1.642): 0.325*\"周姓\" + 0.238*\"華岡藝校\" + 0.191*\"教育局\" + 0.181*\"侵害\" + 0.159*\"權利\" + 0.143*\"校方\" + 0.138*\"行政訴訟\" + 0.138*\"馮喬蘭\" + 0.138*\"學生會\" + 0.119*\"大過\"\n",
      "2017-02-22 19:33:12,058 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n",
      "2017-02-22 19:33:12,099 : INFO : creating matrix with 141 documents and 10 features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of news is :141\n",
      "[('學生', 102), ('員工', 54), ('學校', 21), ('台鐵', 21), ('離職', 20), ('表示', 15), ('公司', 13), ('學習', 12), ('大學', 12), ('獎學金', 12)]\n",
      "['學校', '台鐵', '離職', '表示', '公司']\n",
      "4nd keywords:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-22 19:38:09,409 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2017-02-22 19:38:09,468 : INFO : built Dictionary(6145 unique tokens: ['被告', '派出', '本份', '本件', '不過']...) from 41 documents (total 20446 corpus positions)\n",
      "2017-02-22 19:38:09,501 : INFO : collecting document frequencies\n",
      "2017-02-22 19:38:09,507 : INFO : PROGRESS: processing document #0\n",
      "2017-02-22 19:38:09,510 : INFO : calculating IDF weights for 41 documents and 6144 features (12355 matrix non-zeros)\n",
      "2017-02-22 19:38:09,521 : INFO : using serial LSI version on this node\n",
      "2017-02-22 19:38:09,524 : INFO : updating model with new documents\n",
      "2017-02-22 19:38:09,578 : INFO : preparing a new chunk of documents\n",
      "2017-02-22 19:38:09,584 : INFO : using 100 extra samples and 2 power iterations\n",
      "2017-02-22 19:38:09,591 : INFO : 1st phase: constructing (6145, 110) action matrix\n",
      "2017-02-22 19:38:09,599 : INFO : orthonormalizing (6145, 110) action matrix\n",
      "2017-02-22 19:38:10,197 : INFO : 2nd phase: running dense svd on (110, 41) matrix\n",
      "2017-02-22 19:38:10,224 : INFO : computing the final decomposition\n",
      "2017-02-22 19:38:10,238 : INFO : keeping 10 factors (discarding 64.819% of energy spectrum)\n",
      "2017-02-22 19:38:10,241 : INFO : processed documents up to #41\n",
      "2017-02-22 19:38:10,248 : INFO : topic #0(1.835): 0.372*\"台鐵\" + 0.216*\"休假\" + 0.195*\"春節\" + 0.195*\"曠職\" + 0.160*\"產業工會\" + 0.158*\"台鐵局\" + 0.157*\"員工\" + 0.156*\"交通部\" + 0.123*\"罷工\" + 0.123*\"依法\"\n",
      "2017-02-22 19:38:10,254 : INFO : topic #1(1.376): -0.259*\"離職\" + -0.226*\"老闆\" + -0.204*\"學生\" + -0.185*\"我\" + -0.164*\"坊\" + 0.159*\"台鐵\" + -0.146*\"你\" + -0.145*\"烘焙\" + -0.137*\"萬元\" + -0.122*\"契約\"\n",
      "2017-02-22 19:38:10,257 : INFO : topic #2(1.223): -0.446*\"我\" + -0.146*\"矽谷\" + 0.144*\"學生\" + 0.130*\"坊\" + 0.129*\"離職\" + -0.129*\"公司\" + 0.115*\"烘焙\" + -0.110*\"自己\" + -0.103*\"這些\" + -0.103*\"...\"\n",
      "2017-02-22 19:38:10,262 : INFO : topic #3(1.104): 0.240*\"評鑑\" + 0.227*\"學校\" + -0.186*\"我\" + 0.118*\"華岡藝校\" + 0.116*\"教育部\" + 0.111*\"選舉\" + -0.100*\"離職\" + 0.100*\"農會\" + 0.092*\"延後\" + 0.087*\"到校\"\n",
      "2017-02-22 19:38:10,263 : INFO : topic #4(1.065): -0.227*\"學校\" + -0.217*\"評鑑\" + 0.151*\"遊覽車\" + 0.141*\"司機\" + 0.138*\"旅行社\" + 0.136*\"公路總局\" + 0.130*\"蝶戀花\" + -0.120*\"學生\" + -0.117*\"華岡藝校\" + 0.111*\"長\"\n",
      "2017-02-22 19:38:10,264 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n",
      "2017-02-22 19:38:10,282 : INFO : creating matrix with 41 documents and 10 features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of news is :41\n",
      "[('台鐵', 25), ('員工', 16), ('休假', 16), ('公司', 16), ('表示', 12), ('曠職', 8), ('學校', 7), ('學生', 6), ('離職', 6), ('春節', 5)]\n",
      "['休假', '曠職', '春節']\n"
     ]
    }
   ],
   "source": [
    "%run main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /home/skydome20/Desktop/dbot/dbot.py3/jieba_dict/dict.txt.big ...\n",
      "Loading model from cache /tmp/jieba.u300776cf1c5f564361e07846b411a882.cache\n",
      "Loading model cost 1.677 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "Building prefix dict from /home/skydome20/Desktop/dbot/dbot.py3/jieba_dict/dict.txt.big ...\n",
      "2017-02-23 01:14:53,521 : DEBUG : Building prefix dict from /home/skydome20/Desktop/dbot/dbot.py3/jieba_dict/dict.txt.big ...\n",
      "Loading model from cache /tmp/jieba.u300776cf1c5f564361e07846b411a882.cache\n",
      "2017-02-23 01:14:53,529 : DEBUG : Loading model from cache /tmp/jieba.u300776cf1c5f564361e07846b411a882.cache\n",
      "Loading model cost 2.159 seconds.\n",
      "2017-02-23 01:14:55,689 : DEBUG : Loading model cost 2.159 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "2017-02-23 01:14:55,698 : DEBUG : Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= No filter ===============\n",
      "1st keywords:['女', '大生', '去', '麵包', '坊', '實習', '被', '索賠']\n",
      "2nd keywords:The number of news is :11\n",
      "[('麵包', 8), ('工房', 8), ('員工', 7), ('封存', 5), ('黃士', 4), ('預算', 4), ('蛋糕', 3), ('實習', 3), ('學生', 3), ('核四', 3)]\n",
      "['工房', '員工', '封存', '黃士', '預算']\n",
      "3rd keywords:The number of news is :128\n",
      "[('員工', 105), ('台鐵', 34), ('預算', 28), ('公司', 25), ('離職', 17), ('工作', 15), ('曠職', 15), ('休假', 13), ('學生', 11), ('主管', 9)]\n",
      "['台鐵', '公司', '離職', '工作', '曠職']\n",
      "4nd keywords:The number of news is :117\n",
      "[('台鐵', 68), ('員工', 47), ('工作', 44), ('公司', 42), ('離職', 26), ('休假', 25), ('曠職', 18), ('學生', 18), ('公司法', 13), ('求償', 11)]\n",
      "['休假', '學生', '公司法', '求償']\n"
     ]
    }
   ],
   "source": [
    "%run main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /home/skydome20/Desktop/dbot/dbot.py3/jieba_dict/dict.txt.big ...\n",
      "Loading model from cache /tmp/jieba.u300776cf1c5f564361e07846b411a882.cache\n",
      "Loading model cost 1.831 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "Building prefix dict from /home/skydome20/Desktop/dbot/dbot.py3/jieba_dict/dict.txt.big ...\n",
      "2017-02-23 11:36:36,868 : DEBUG : Building prefix dict from /home/skydome20/Desktop/dbot/dbot.py3/jieba_dict/dict.txt.big ...\n",
      "Loading model from cache /tmp/jieba.u300776cf1c5f564361e07846b411a882.cache\n",
      "2017-02-23 11:36:36,875 : DEBUG : Loading model from cache /tmp/jieba.u300776cf1c5f564361e07846b411a882.cache\n",
      "Loading model cost 2.342 seconds.\n",
      "2017-02-23 11:36:39,217 : DEBUG : Loading model cost 2.342 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "2017-02-23 11:36:39,225 : DEBUG : Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Similar filter ===============\n",
      "1st keywords:['Uber', '罰款', '議題']\n",
      "2nd keywords:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-23 11:47:26,758 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2017-02-23 11:47:26,853 : INFO : built Dictionary(8721 unique tokens: ['所謂', '性別歧視', '前提', '上線', '一次']...) from 114 documents (total 44769 corpus positions)\n",
      "2017-02-23 11:47:26,961 : INFO : collecting document frequencies\n",
      "2017-02-23 11:47:26,974 : INFO : PROGRESS: processing document #0\n",
      "2017-02-23 11:47:26,988 : INFO : calculating IDF weights for 114 documents and 8720 features (27081 matrix non-zeros)\n",
      "2017-02-23 11:47:27,009 : INFO : using serial LSI version on this node\n",
      "2017-02-23 11:47:27,019 : INFO : updating model with new documents\n",
      "2017-02-23 11:47:27,116 : INFO : preparing a new chunk of documents\n",
      "2017-02-23 11:47:27,133 : INFO : using 100 extra samples and 2 power iterations\n",
      "2017-02-23 11:47:27,147 : INFO : 1st phase: constructing (8721, 110) action matrix\n",
      "2017-02-23 11:47:27,175 : INFO : orthonormalizing (8721, 110) action matrix\n",
      "2017-02-23 11:47:28,028 : INFO : 2nd phase: running dense svd on (110, 114) matrix\n",
      "2017-02-23 11:47:28,056 : INFO : computing the final decomposition\n",
      "2017-02-23 11:47:28,065 : INFO : keeping 10 factors (discarding 74.240% of energy spectrum)\n",
      "2017-02-23 11:47:28,069 : INFO : processed documents up to #114\n",
      "2017-02-23 11:47:28,077 : INFO : topic #0(2.535): 0.291*\"Uber\" + 0.172*\"司機\" + 0.126*\"交通部\" + 0.121*\"計程車\" + 0.119*\"合作\" + 0.117*\"台灣\" + 0.104*\"議題\" + 0.103*\"唐鳳\" + 0.099*\"服務\" + 0.092*\"乘客\"\n",
      "2017-02-23 11:47:28,083 : INFO : topic #1(2.041): -0.256*\"國是會議\" + -0.240*\"司法\" + -0.236*\"議題\" + -0.216*\"委員\" + -0.210*\"司改\" + -0.197*\"檢察官\" + -0.170*\"法官\" + 0.160*\"Uber\" + -0.148*\"改革\" + -0.136*\"會議\"\n",
      "2017-02-23 11:47:28,085 : INFO : topic #2(1.729): -0.368*\"越南交通\" + -0.339*\"部\" + -0.316*\"Vietnam\" + -0.287*\"越南\" + -0.256*\"客運\" + -0.229*\"應用\" + -0.133*\"規定\" + -0.131*\"活動\" + -0.131*\"經營\" + -0.119*\"提案\"\n",
      "2017-02-23 11:47:28,090 : INFO : topic #3(1.672): -0.301*\"唐鳳\" + 0.280*\"張仙\" + 0.173*\"平\" + -0.169*\"方案\" + -0.168*\"多元化\" + 0.143*\"產業\" + -0.126*\"退出\" + 0.122*\"導入\" + 0.122*\"營運模式\" + 0.122*\"Taiwan\"\n",
      "2017-02-23 11:47:28,091 : INFO : topic #4(1.587): 0.334*\"唐鳳\" + 0.186*\"方案\" + 0.182*\"多元化\" + 0.165*\"張仙\" + -0.141*\"合作\" + 0.140*\"退出\" + -0.122*\"租賃\" + -0.109*\"萬元\" + 0.101*\"平\" + -0.096*\"車公\"\n",
      "2017-02-23 11:47:28,094 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n",
      "2017-02-23 11:47:28,116 : INFO : creating matrix with 114 documents and 10 features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of news is :114\n",
      "[('台灣', 57), ('uber', 54), ('議題', 42), ('司機', 42), ('服務', 30), ('計程車', 18), ('合作', 17), ('司法', 16), ('政府', 16), ('公司', 15)]\n",
      "['台灣', 'uber', '司機', '服務', '計程車']\n",
      "3rd keywords:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-23 11:57:52,254 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2017-02-23 11:57:52,441 : INFO : built Dictionary(15915 unique tokens: ['登記', '性別歧視', '前提', '13支', '頁']...) from 159 documents (total 69312 corpus positions)\n",
      "2017-02-23 11:57:52,615 : INFO : collecting document frequencies\n",
      "2017-02-23 11:57:52,626 : INFO : PROGRESS: processing document #0\n",
      "2017-02-23 11:57:52,648 : INFO : calculating IDF weights for 159 documents and 15914 features (43919 matrix non-zeros)\n",
      "2017-02-23 11:57:52,691 : INFO : using serial LSI version on this node\n",
      "2017-02-23 11:57:52,697 : INFO : updating model with new documents\n",
      "2017-02-23 11:57:52,866 : INFO : preparing a new chunk of documents\n",
      "2017-02-23 11:57:52,902 : INFO : using 100 extra samples and 2 power iterations\n",
      "2017-02-23 11:57:52,908 : INFO : 1st phase: constructing (15915, 110) action matrix\n",
      "2017-02-23 11:57:52,935 : INFO : orthonormalizing (15915, 110) action matrix\n",
      "2017-02-23 11:57:54,756 : INFO : 2nd phase: running dense svd on (110, 159) matrix\n",
      "2017-02-23 11:57:54,804 : INFO : computing the final decomposition\n",
      "2017-02-23 11:57:54,811 : INFO : keeping 10 factors (discarding 79.871% of energy spectrum)\n",
      "2017-02-23 11:57:54,816 : INFO : processed documents up to #159\n",
      "2017-02-23 11:57:54,846 : INFO : topic #0(2.296): 0.440*\"Uber\" + 0.234*\"司機\" + 0.172*\"計程車\" + 0.152*\"遊覽車\" + 0.133*\"駕駛\" + 0.120*\"交通部\" + 0.116*\"服務\" + 0.087*\"我\" + 0.084*\"UB\" + 0.084*\"ER\"\n",
      "2017-02-23 11:57:54,851 : INFO : topic #1(1.812): 0.611*\"Uber\" + -0.247*\"遊覽車\" + 0.149*\"計程車\" + -0.139*\"司機\" + -0.130*\"小時\" + -0.129*\"休息\" + -0.127*\"蝶戀花\" + -0.110*\"旅行社\" + -0.106*\"工時\" + -0.102*\"駕駛\"\n",
      "2017-02-23 11:57:54,862 : INFO : topic #2(1.680): -0.214*\"遊覽車\" + -0.212*\"司機\" + -0.170*\"Uber\" + -0.162*\"駕駛\" + 0.157*\"紅藜\" + 0.118*\"我\" + 0.114*\"企業\" + -0.105*\"休息\" + 0.103*\"%\" + -0.099*\"小時\"\n",
      "2017-02-23 11:57:54,864 : INFO : topic #3(1.554): -0.563*\"紅藜\" + -0.275*\"大腸癌\" + 0.201*\"海域\" + 0.198*\"原能會\" + 0.180*\"核廢料\" + -0.155*\"病變\" + -0.144*\"前期\" + 0.142*\"查證\" + -0.130*\"預防\" + 0.117*\"義大利\"\n",
      "2017-02-23 11:57:54,865 : INFO : topic #4(1.541): -0.339*\"紅藜\" + -0.275*\"海域\" + -0.270*\"原能會\" + -0.246*\"核廢料\" + -0.195*\"查證\" + -0.174*\"大腸癌\" + -0.159*\"義大利\" + -0.156*\"傾倒\" + 0.137*\"我\" + -0.131*\"輻射\"\n",
      "2017-02-23 11:57:54,868 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n",
      "2017-02-23 11:57:54,922 : INFO : creating matrix with 159 documents and 10 features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of news is :159\n",
      "[('台灣', 131), ('司機', 50), ('服務', 23), ('遊覽車', 21), ('計程車', 18), ('駕駛', 14), ('日本', 12), ('政府', 11), ('小時', 11), ('工時', 9)]\n",
      "['遊覽車', '駕駛', '日本', '政府', '小時']\n",
      "4nd keywords:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-23 12:10:16,692 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2017-02-23 12:10:16,837 : INFO : built Dictionary(14041 unique tokens: ['穎', '前提', '外來物種', '與究責', '詢於芻蕘']...) from 143 documents (total 64289 corpus positions)\n",
      "2017-02-23 12:10:16,966 : INFO : collecting document frequencies\n",
      "2017-02-23 12:10:16,975 : INFO : PROGRESS: processing document #0\n",
      "2017-02-23 12:10:16,996 : INFO : calculating IDF weights for 143 documents and 14040 features (39412 matrix non-zeros)\n",
      "2017-02-23 12:10:17,035 : INFO : using serial LSI version on this node\n",
      "2017-02-23 12:10:17,047 : INFO : updating model with new documents\n",
      "2017-02-23 12:10:17,202 : INFO : preparing a new chunk of documents\n",
      "2017-02-23 12:10:17,225 : INFO : using 100 extra samples and 2 power iterations\n",
      "2017-02-23 12:10:17,240 : INFO : 1st phase: constructing (14041, 110) action matrix\n",
      "2017-02-23 12:10:17,270 : INFO : orthonormalizing (14041, 110) action matrix\n",
      "2017-02-23 12:10:18,290 : INFO : 2nd phase: running dense svd on (110, 143) matrix\n",
      "2017-02-23 12:10:18,333 : INFO : computing the final decomposition\n",
      "2017-02-23 12:10:18,338 : INFO : keeping 10 factors (discarding 79.853% of energy spectrum)\n",
      "2017-02-23 12:10:18,348 : INFO : processed documents up to #143\n",
      "2017-02-23 12:10:18,353 : INFO : topic #0(2.562): 0.260*\"駕駛\" + 0.207*\"遊覽車\" + 0.168*\"行程\" + 0.146*\"司機\" + 0.123*\"一日遊\" + 0.120*\"雙\" + 0.117*\"旅遊\" + 0.116*\"小時\" + 0.114*\"休息\" + 0.111*\"業者\"\n",
      "2017-02-23 12:10:18,367 : INFO : topic #1(1.678): 0.183*\"一日遊\" + 0.178*\"行程\" + 0.142*\"雙\" + -0.135*\"通運\" + 0.125*\"駕駛\" + 0.124*\"旅遊\" + -0.118*\"安全帶\" + 0.116*\"替換\" + 0.110*\"燦星\" + 0.108*\"國旅\"\n",
      "2017-02-23 12:10:18,382 : INFO : topic #2(1.525): -0.477*\"通運\" + -0.267*\"汽車\" + -0.151*\"客運\" + -0.147*\"遊覽車\" + 0.123*\"政府\" + 0.111*\"日本\" + -0.109*\"公路總局\" + -0.106*\"有限公司\" + 0.105*\"年金改革\" + -0.096*\"統聯\"\n",
      "2017-02-23 12:10:18,384 : INFO : topic #3(1.507): 0.310*\"通運\" + -0.186*\"工時\" + 0.159*\"汽車\" + -0.155*\"駕駛\" + -0.144*\"休息\" + -0.143*\"甲\" + -0.140*\"勞動部\" + -0.131*\"小時\" + 0.124*\"客運\" + -0.102*\"乙\"\n",
      "2017-02-23 12:10:18,385 : INFO : topic #4(1.415): 0.204*\"安全帶\" + -0.180*\"通運\" + 0.142*\"行程\" + -0.136*\"雙\" + 0.130*\"乘客\" + 0.114*\"白志偉\" + -0.105*\"政府\" + -0.102*\"甲\" + -0.101*\"駕駛\" + -0.100*\"年金改革\"\n",
      "2017-02-23 12:10:18,391 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n",
      "2017-02-23 12:10:18,435 : INFO : creating matrix with 143 documents and 10 features\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of news is :143\n",
      "[('遊覽車', 85), ('駕駛', 69), ('日本', 52), ('政府', 34), ('司機', 31), ('行程', 24), ('小時', 18), ('旅遊', 18), ('工時', 17), ('表示', 17)]\n",
      "['行程', '旅遊', '工時', '表示']\n"
     ]
    }
   ],
   "source": [
    "%run main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /home/skydome20/Desktop/dbot/dbot.py3/jieba_dict/dict.txt.big ...\n",
      "Loading model from cache /tmp/jieba.u300776cf1c5f564361e07846b411a882.cache\n",
      "Loading model cost 1.573 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "Building prefix dict from /home/skydome20/Desktop/dbot/dbot.py3/jieba_dict/dict.txt.big ...\n",
      "2017-02-23 14:07:46,355 : DEBUG : Building prefix dict from /home/skydome20/Desktop/dbot/dbot.py3/jieba_dict/dict.txt.big ...\n",
      "Loading model from cache /tmp/jieba.u300776cf1c5f564361e07846b411a882.cache\n",
      "2017-02-23 14:07:46,362 : DEBUG : Loading model from cache /tmp/jieba.u300776cf1c5f564361e07846b411a882.cache\n",
      "Loading model cost 2.252 seconds.\n",
      "2017-02-23 14:07:48,614 : DEBUG : Loading model cost 2.252 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "2017-02-23 14:07:48,622 : DEBUG : Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= No filter ===============\n",
      "1st keywords:['Uber', '罰款', '議題']\n",
      "2nd keywords:The number of news is :120\n",
      "[('台灣', 55), ('uber', 53), ('議題', 46), ('司機', 42), ('服務', 31), ('司法', 19), ('計程車', 18), ('合作', 17), ('討論', 16), ('委員', 16)]\n",
      "['台灣', 'uber', '司機', '服務', '司法']\n",
      "3rd keywords:The number of news is :158\n",
      "[('台灣', 116), ('司機', 49), ('服務', 20), ('司法', 18), ('遊覽車', 16), ('日本', 15), ('小時', 13), ('計程車', 12), ('貿易', 11), ('駕駛', 10)]\n",
      "['遊覽車', '日本', '小時', '計程車', '貿易']\n",
      "4nd keywords:The number of news is :143\n",
      "[('遊覽車', 83), ('日本', 66), ('駕駛', 34), ('司機', 31), ('台灣', 30), ('貿易', 24), ('小時', 16), ('計程車', 12), ('行程', 12), ('表示', 11)]\n",
      "['駕駛', '行程', '表示']\n"
     ]
    }
   ],
   "source": [
    "%run main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
